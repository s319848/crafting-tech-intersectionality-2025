# crafting-tech-intersectionality-2025
This repository contains the code written to carry out the experiments for the project of the course "Crafting Tech", 2025 edition, for the project "AI Intersectionality"

```CT_semantic_analysis.ipynb```

This file contains all the semantic analysis carried out to evaluate the comprehensivness and novelty of the risks generated by each focus group, for all uses.

First the distribution of the pair-wise BERTScore (bert-score library necessary) is explored through its quantiles, then once the threshold to consider a risk to be "matched" has been established, the overlap between generated risks and baseline (and vice versa) is computed, together with the tables for "common uses" and "overlooked uses" and desired visualizations.


```risks```

This folder contains all the risks generated by every focus group separated per use.


```Extract_risks_focus_group_plurals.ipynb```

This file contains the code that was used to simulate the focus groups from which risks associated to each use are generated.

Plurals library is necessary. To better understand the implementation of the different functionalities, refer to the Plurals documentation (https://josh-ashkinaze.github.io/plurals/) or the Plurals paper (https://arxiv.org/abs/2409.17213).

Plurals samples personas from the ANES database (https://electionstudies.org/data-center/), according to specified characteristics.
First we instantiate a "general" focus group of 100 people with random characteristics. Then we instantiate a "black women" focus group, comprised of 100 individuals from the ANES database with gender='woman' and race='black'. Finally, we instantiate a focus group with 100 people with oppressed characteristics, sampled following the distribution of people with at least two oppressed characteristics from the ANES database.

The focus groups discuss the possible risks of facial recognition technology (the use has been manually changed in the prompt, re-executing the cell every time and saving manually the results). Then a moderator is tasked to summarize the most relevant risks, providing examples from ExploreGen to adopt a similar (and therefore comparable) format (but specifying not to copy the content).


```evaluate_risks.py```

This file has been used to obtain the scores for each risk related to each use. 
The same questions are asked to an LLM (through a manually crafted prompt) and the results are obtained for the single use, then manually aggregated.


```calculate_accuracy.py```

Once we have both the labelling of human AI experts and the labelling of the LLM (for the subset of risks that we evaluate with Prolific), we can evaluate different metrics to validate the output of the LLM. For each label (question related to a risk) we calculate accuracy, adjacent accuracy (meaning that a value is considered to be correct if it falls between +-1 of the ground truth), MSE and RMSE.


```LLM_comparison.xlsx```

This file contains the comparison between the score given to each question by human experts (or by us, in case of non-consensus between experts) and by the LLM. for the subset of risks used to validate the LLM. The score of the LLM is comprehensive of the reasoning behind the answer.


```Prolific_answers_analysis.xlsx```

This Excel file contains three sheets, all containing the answers to the questions submitted on Prolific. Sheet #1 contains a preliminar analysis of the answers, looking at which group of three answers to the same question had a majority (that becomes the "official" answer), which ones did not have a consensus but had a trend or strong trend towards a sentiment (positive or negative) and which one did not have a consensus at all.

Sheet #2 refines this analysis, manually labelling the questions with a trend through an arbitrary decision, and identifying which questions had several "non-consensus" answers (PROBLEM). We then decided to keep all the questions, since none of the problems appear to be critical (no question had always non-consensus, for example).

The final result can be observed in the third sheet, "Labeled by experts"


```labelled_risks```

This folder contains the score given by the LLM to each risk for each statement, divided by focus group.

Each file reports the results for a single use, and a separate file reports the results for the risks obtained from ExploreGen, all together.


```Labelling graphs```

This folder contains the two files used to create the graphs for the labelling of each risk.

Each file contains different sheets, one per use plus one for ExploreGen. For every risk it contains the average score for every identity axes and the total average score (for each axes) of all risks.


```ResponsibleAI_2025-5-12_PROJECT_with_comments.zip```

This zip folder contains the output of the tool https://social-dynamics.net/rai-guidelines/ . Additionally, we insert in the folder a file named "unclear_cards.txt" which contains a brief description and motivation for the three cards that we found the most difficult to understand.



